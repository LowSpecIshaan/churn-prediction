


import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
df = pd.read_excel("Telco Churn dataset.xlsx")
df.head()





df.shape


df.columns


df.info()


df.describe()


df.isnull().sum()


df['Churn'].value_counts()


rows_to_remove = df[df["Churn"] == "No"].sample(n=2350, random_state=42)
df = df.drop(rows_to_remove.index)


import matplotlib.pyplot as plt

df.hist(figsize=(12,10))

plt.suptitle("Feature Distributions in Telco Churn Dataset", fontsize=16)
plt.xlabel("Feature Values")
plt.ylabel("Frequency")

plt.tight_layout()
plt.show()





# Dropping TotalCall as it is Redundant
df = df.drop(columns=["TotalCall"])


# Encoding Yes and No to 1 and 0
df.MaritalStatus.unique()


cols = ["MaritalStatus", "OnlineSecurity", "OnlineBackup", "Dependents", "DeviceProtection", "TechSupport", "StreamingTV", "MultipleLines", "StreamingMovies", "PaperlessBilling", "InternationalPlan", "VoiceMailPlan", "Churn", "PhoneService"]

for col in cols:
    df[col] = df[col].replace({"Yes": 1, "No": 0, "No internet service": 2})


df


df["gender"] = df["gender"].replace({"Male": 0, "Female": 1})
df


df["InternetService"].unique()


df = pd.get_dummies(df, columns=["InternetService"], drop_first=True)
df = pd.get_dummies(df, columns=["Contract"], drop_first=True)
df = pd.get_dummies(df, columns=["PaymentMethod"], drop_first=True)
df


import seaborn as sns
sns.heatmap(df.corr(numeric_only=True))


df = df.drop("customerID", axis=1)

df[df.eq(" ").any(axis=1)]

df = df[~df.eq(" ").any(axis=1)]
df["TotalRevenue"] = pd.to_numeric(df["TotalRevenue"], errors="coerce")
df = df.dropna(subset=["TotalRevenue"])
print(df["TotalRevenue"].dtype)


X = df.drop("Churn", axis=1)
y = df["Churn"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)





model = LogisticRegression(max_iter=2000, class_weight="balanced")
model.fit(X_train, y_train)


y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]


from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))


rf = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    class_weight="balanced"
)

rf.fit(X_train, y_train)


y_pred_rf = rf.predict(X_test)
y_prob_rf = rf.predict_proba(X_test)[:, 1]


print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))


from xgboost import XGBClassifier

xgb = XGBClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    random_state=42,
    use_label_encoder=False,
    eval_metric="logloss"
)

xgb.fit(X_train, y_train)


y_pred_xgb = xgb.predict(X_test)
y_prob_xgb = xgb.predict_proba(X_test)[:, 1]


print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))
print("\nClassification Report:\n", classification_report(y_test, y_pred_xgb))


from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(
    y_test,
    y_pred_xgb,
    display_labels=["No Churn", "Churn"]
)

plt.title("Confusion Matrix - XGBoost")
plt.show()


import joblib

joblib.dump(xgb, "xgboost_model.pkl")
